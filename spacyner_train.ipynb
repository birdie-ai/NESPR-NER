{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"spacyner_train.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3E_OlrQdz4Tp","executionInfo":{"status":"ok","timestamp":1620760538487,"user_tz":180,"elapsed":86796,"user":{"displayName":"João Leite","photoUrl":"","userId":"06497342697868808268"}},"outputId":"34d0f905-803d-4682-fb4c-e09cdee32619"},"source":["!pip install spacy==3.0.6 --quiet\n","!python -m spacy download en_core_web_trf --quiet\n","!pip install spacy-lookups-data --quiet"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 12.8MB 212kB/s \n","\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n","\u001b[K     |████████████████████████████████| 460kB 39.9MB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 40.7MB/s \n","\u001b[K     |████████████████████████████████| 9.1MB 52.9MB/s \n","\u001b[K     |████████████████████████████████| 122kB 51.6MB/s \n","\u001b[?25h  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n","2021-05-11 19:14:39.840013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","\u001b[K     |████████████████████████████████| 459.7MB 35kB/s \n","\u001b[K     |████████████████████████████████| 1.0MB 42.6MB/s \n","\u001b[K     |████████████████████████████████| 2.1MB 42.6MB/s \n","\u001b[K     |████████████████████████████████| 901kB 53.2MB/s \n","\u001b[K     |████████████████████████████████| 3.3MB 47.9MB/s \n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_trf')\n","\u001b[K     |████████████████████████████████| 93.4MB 33kB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQMZWozXMeH8","executionInfo":{"status":"ok","timestamp":1620760595481,"user_tz":180,"elapsed":143673,"user":{"displayName":"João Leite","photoUrl":"","userId":"06497342697868808268"}},"outputId":"eba2179d-9889-477d-b8b3-a19c6aba1821"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PXQlvOl_qqoY"},"source":["# config file\n","!cp drive/MyDrive/ner/model_config/config.cfg .\n","\n","# train file\n","!cp drive/MyDrive/ner/data/laptop-ner.json ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uI2GQfECwJea"},"source":["import pandas as pd\n","from sklearn.model_selection import KFold\n","from spacy.tokens import DocBin, Span\n","from spacy.util import filter_spans\n","from tqdm import tqdm\n","from pathlib import Path\n","import json\n","import spacy\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7KkCXmaAwQmY"},"source":["class CFG:\n","    seed = 42\n","    labels = [\n","        \"PRODUCT\",\n","        \"POS_EXP\",\n","        \"ISSUE\",\n","        \"BRAND\",\n","        \"ATTR\",\n","        \"PERSON\",\n","        \"CONTXT_USE\",\n","        \"RETAILER\"\n","    ]\n","    balance_labels = False\n","    single_model = False\n","    filename = \"laptop-ner.json\"\n","    exp_name = \"A\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6wZf-hA63bW9"},"source":["def separate_data():\n","    examples = []\n","\n","    with open(CFG.filename) as f:\n","        for line in f.readlines():\n","            example = json.loads(line)\n","            spans = example.get(\"spans\")\n","            if spans:\n","                ents = {\"entities\": []}\n","                for span in spans:\n","                    start = span[\"start\"]\n","                    end = span[\"end\"] \n","                    ents[\"entities\"].append((start, end, span[\"label\"]))\n","                \n","                new_example = (example[\"text\"], ents)\n","                examples.append(new_example)\n","\n","    return examples\n","\n","def separate_data_exclusive():\n","    \"\"\"\n","    separate overlapping spans into unique non-overlapping sentences\n","    ex: samsung is great\n","        -BRAND-\n","        ----POS_EXP---\n","\n","    becomes two sentences\n","    a)\n","    samsung is great\n","    -BRAND-\n","    b)\n","    samsung is great\n","    ----POS_EXP----\n","\n","    also returns a dict of {sentence: [labels]}\n","    so that we can lookup which labels the original sentence had\n","    \"\"\"\n","    sent_label_lookup = {}\n","    examples = {}\n","\n","    for label in CFG.labels:\n","        examples[label] = []\n","\n","    with open(CFG.filename) as f:\n","        for line in f.readlines():\n","            example = json.loads(line)\n","            for label in CFG.labels:\n","                flag_match = 0\n","                spans = example.get(\"spans\")\n","                global_ents = []\n","                if spans:\n","                    sep_ents = {\"entities\": []}\n","                    for span in spans:\n","                        global_ents.append(span[\"label\"])\n","                        if span[\"label\"] == label:\n","                            flag_match = 1\n","                            start = span[\"start\"]\n","                            end = span[\"end\"] \n","\n","                            sep_ents[\"entities\"].append((start, end, label))\n","                else:\n","                    flag_match = 0\n","                \n","                if flag_match:\n","                    new_example = (example[\"text\"], sep_ents)\n","                    examples[label].append(new_example)\n","                \n","                sent_label_lookup[example[\"text\"]] = global_ents\n","\n","    return examples, sent_label_lookup\n","\n","def balance_examples(examples, ex_label_pairing):\n","    for label in CFG.labels:\n","        pos_ex = len(examples[label])\n","        neg_ex = 0\n","        for ex, entities in ex_label_pairing.items():\n","            if neg_ex == pos_ex:\n","                break\n","            else:\n","                if label not in ex_label_pairing:\n","                    examples[label].append((ex, {\"entities\": []}))\n","                    neg_ex += 1\n","\n","    return examples\n","\n","def data_to_spacy(examples):\n","    \"\"\"convert annotations to spacy format\"\"\"\n","    nlp = spacy.blank(\"en\") # load a new spacy model\n","    for label in tqdm(CFG.labels):\n","        for i in range(5):\n","            kf = KFold(n_splits=2, shuffle=True, random_state=CFG.seed)\n","            k = 1\n","            for train_idxs, test_idxs in kf.split(examples[label]):\n","                train = list(map(examples[label].__getitem__, train_idxs))\n","                test = list(map(examples[label].__getitem__, test_idxs))\n","\n","                train_db = DocBin()\n","                test_db = DocBin()\n","                for text, annot in train: # data in previous format\n","                    doc = nlp.make_doc(text) # create doc object from text\n","                    ents = []\n","                    for start, end, label in annot[\"entities\"]: # add character indexes\n","                        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n","                        if span is None:\n","                            print(\"Skipping entity\")\n","                        else:\n","                            ents.append(span)\n","                    try:\n","                        doc.ents = ents # label the text with the ents\n","                        train_db.add(doc)\n","                    except:\n","                        pass\n","\n","                train_db.to_disk(f\"./{CFG.exp_name}-train-{label}-it{i+1}-fold{k}.spacy\")\n","\n","                for text, annot in test: # data in previous format\n","                    doc = nlp.make_doc(text) # create doc object from text\n","                    ents = []\n","                    for start, end, label in annot[\"entities\"]: # add character indexes\n","                        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n","                        if span is None:\n","                            pass\n","                        else:\n","                            ents.append(span)\n","                    try:\n","                        doc.ents = ents # label the text with the ents\n","                        test_db.add(doc)\n","                    except:\n","                        continue\n","\n","                test_db.to_disk(f\"./{CFG.exp_name}-dev-{label}-it{i+1}-fold{k}.spacy\")\n","                \n","                k += 1\n","\n","def get_longest_span(examples):\n","    new_examples = []\n","    nlp = spacy.blank(\"en\")\n","    for example in examples:\n","        # construct filter class and filter spans\n","        text = example[0]\n","        spans = example[1][\"entities\"]\n","        doc = nlp(text)\n","        ents = []\n","        for span in spans:\n","            char_span = doc.char_span(\n","                span[0],\n","                span[1],\n","                label=span[2],\n","                alignment_mode=\"contract\"\n","            )\n","            ents.append(char_span)\n","\n","        filtered_spans = filter_spans(ents)\n","        formatted_spans = []\n","        # reshape into original formatting\n","        for filtered_span in filtered_spans:\n","            start = filtered_span.start_char\n","            end = filtered_span.end_char\n","            label = filtered_span.label_\n","\n","            formatted_spans.append((start, end, label))\n","\n","        new_examples.append((text, {\"entities\": formatted_spans}))\n","    return new_examples\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qdWV-EQuDWX2"},"source":["examples = separate_data()\n","long_examples = get_longest_span(examples)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"luhyd6YOMY7p"},"source":["if CFG.single_model:\n","    examples = separate_data()\n","else:\n","    examples, ex_label_pairing = separate_data_exclusive()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYoN12qluig9"},"source":["if CFG.balance_labels:\n","    examples = balance_examples(examples, ex_label_pairing)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dLgXUXfS1GjX","executionInfo":{"status":"ok","timestamp":1620742160940,"user_tz":180,"elapsed":415,"user":{"displayName":"João Leite","photoUrl":"","userId":"06497342697868808268"}},"outputId":"904cc0ee-dbe4-4fed-8cc4-8583dd642a13"},"source":["for label, exs in examples.items():\n","    print(label, len(exs))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["PRODUCT 841\n","POS_EXP 1066\n","ISSUE 1042\n","BRAND 325\n","ATTR 2139\n","PERSON 140\n","CONTXT_USE 668\n","RETAILER 81\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2caOWvwK13CV","executionInfo":{"status":"ok","timestamp":1620742241298,"user_tz":180,"elapsed":79497,"user":{"displayName":"João Leite","photoUrl":"","userId":"06497342697868808268"}},"outputId":"1cebbd05-9379-4f80-9f73-ff6001f4eb12"},"source":["data_to_spacy(examples)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 8/8 [01:16<00:00,  9.60s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"r486Ey-_5faD"},"source":["os.environ[\"exp_name\"] = CFG.exp_name"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pYHENEzP3IRE","executionInfo":{"status":"ok","timestamp":1620745774252,"user_tz":180,"elapsed":1314,"user":{"displayName":"João Leite","photoUrl":"","userId":"06497342697868808268"}},"outputId":"57a7cdef-0a85-410b-c672-762349c9ba6e"},"source":["%%writefile train.sh\n","#!/bin/bash\n","echo \"RUNNING EXPERIMENT $exp_name\"\n","for label in ATTR BRAND CONTXT_USE ISSUE PERSON POS_EXP PRODUCT RETAILER\n","do\n","    for i in 1 2 3 4 5\n","    do\n","        for k in 1 2\n","        do\n","            echo \"Training model for $label at fold $k\"\n","            python -m spacy train \"config.cfg\" --output \"./$exp_name-$label-it$i-fold$k\" --paths.train \"$exp_name-train-$label-it$i-fold$k.spacy\" --paths.dev \"$exp_name-dev-$label-it$i-fold$k.spacy\" --gpu-id 0 --training.patience 400 --verbose\n","            zip -FSr $exp_name-$label-it$i-fold$k.zip $exp_name-$label-it$i-fold$k/model-best/*\n","            cp $exp_name-$label-it$i-fold$k.zip \"drive/MyDrive/ner/$exp_name/$label/\"\n","            rm -r $exp_name-$label-it$i-fold$k.zip \"$exp_name-$label-it$i-fold$k\"\n","        done\n","    done\n","done"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting train.sh\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oXurd8oH3XV6","outputId":"f3e4b7bc-205f-405f-8c0c-f7b0e7a7d15f"},"source":["!sh train.sh"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RUNNING EXPERIMENT A\n","Training model for ATTR at fold 1\n","2021-05-11 15:09:36.570066: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","\u001b[38;5;2m✔ Created output directory: A-ATTR-it1-fold1\u001b[0m\n","[2021-05-11 15:09:38,242] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev', 'training.patience']\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2021-05-11 15:09:38,924] [INFO] Set up nlp object from config\n","[2021-05-11 15:09:38,933] [DEBUG] Loading corpus from path: A-dev-ATTR-it1-fold1.spacy\n","[2021-05-11 15:09:38,934] [DEBUG] Loading corpus from path: A-train-ATTR-it1-fold1.spacy\n","[2021-05-11 15:09:38,934] [INFO] Pipeline: ['transformer', 'ner']\n","[2021-05-11 15:09:38,940] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm']\n","[2021-05-11 15:09:38,952] [INFO] Added vocab lookups: lexeme_norm\n","[2021-05-11 15:09:38,952] [INFO] Created vocabulary\n","[2021-05-11 15:09:38,952] [INFO] Finished initializing nlp object\n","[2021-05-11 15:09:44,917] [INFO] Initialized pipeline components: ['transformer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2021-05-11 15:09:44,967] [DEBUG] Loading corpus from path: A-dev-ATTR-it1-fold1.spacy\n","[2021-05-11 15:09:44,968] [DEBUG] Loading corpus from path: A-train-ATTR-it1-fold1.spacy\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  --------  ------  ------  ------  ------\n","  0       0        4143.29    678.11    0.00    0.00    0.00    0.00\n","200     200       98766.62  32082.66   57.95   55.43   60.71    0.58\n","400     400          29.90   1171.93   60.23   57.61   63.10    0.60\n","600     600          15.35   1116.47   59.78   55.00   65.48    0.60\n","800     800          14.78   1075.81   60.00   56.25   64.29    0.60\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","A-ATTR-it1-fold1/model-last\n","  adding: A-ATTR-it1-fold1/model-best/config.cfg (deflated 60%)\n","  adding: A-ATTR-it1-fold1/model-best/meta.json (deflated 58%)\n","  adding: A-ATTR-it1-fold1/model-best/ner/ (stored 0%)\n","  adding: A-ATTR-it1-fold1/model-best/ner/moves (deflated 46%)\n","  adding: A-ATTR-it1-fold1/model-best/ner/cfg (deflated 31%)\n","  adding: A-ATTR-it1-fold1/model-best/ner/model (deflated 8%)\n","  adding: A-ATTR-it1-fold1/model-best/tokenizer (deflated 81%)\n","  adding: A-ATTR-it1-fold1/model-best/transformer/ (stored 0%)\n","  adding: A-ATTR-it1-fold1/model-best/transformer/cfg (stored 0%)\n","  adding: A-ATTR-it1-fold1/model-best/transformer/model/ (stored 0%)\n","  adding: A-ATTR-it1-fold1/model-best/transformer/model/config.json (deflated 49%)\n","  adding: A-ATTR-it1-fold1/model-best/transformer/model/tokenizer_config.json (deflated 47%)\n","  adding: A-ATTR-it1-fold1/model-best/transformer/model/special_tokens_map.json (deflated 50%)\n","  adding: A-ATTR-it1-fold1/model-best/transformer/model/vocab.json (deflated 59%)\n","  adding: A-ATTR-it1-fold1/model-best/transformer/model/pytorch_model.bin (deflated 15%)\n","  adding: A-ATTR-it1-fold1/model-best/transformer/model/merges.txt (deflated 53%)\n","  adding: A-ATTR-it1-fold1/model-best/vocab/ (stored 0%)\n","  adding: A-ATTR-it1-fold1/model-best/vocab/key2row (stored 0%)\n","  adding: A-ATTR-it1-fold1/model-best/vocab/vectors (deflated 45%)\n","  adding: A-ATTR-it1-fold1/model-best/vocab/lookups.bin (deflated 43%)\n","  adding: A-ATTR-it1-fold1/model-best/vocab/strings.json (deflated 72%)\n","Training model for ATTR at fold 2\n","2021-05-11 15:26:01.175983: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","\u001b[38;5;2m✔ Created output directory: A-ATTR-it1-fold2\u001b[0m\n","[2021-05-11 15:26:03,638] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev', 'training.patience']\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2021-05-11 15:26:04,361] [INFO] Set up nlp object from config\n","[2021-05-11 15:26:04,370] [DEBUG] Loading corpus from path: A-dev-ATTR-it1-fold2.spacy\n","[2021-05-11 15:26:04,371] [DEBUG] Loading corpus from path: A-train-ATTR-it1-fold2.spacy\n","[2021-05-11 15:26:04,371] [INFO] Pipeline: ['transformer', 'ner']\n","[2021-05-11 15:26:04,376] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm']\n","[2021-05-11 15:26:04,384] [INFO] Added vocab lookups: lexeme_norm\n","[2021-05-11 15:26:04,384] [INFO] Created vocabulary\n","[2021-05-11 15:26:04,384] [INFO] Finished initializing nlp object\n","[2021-05-11 15:26:10,590] [INFO] Initialized pipeline components: ['transformer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2021-05-11 15:26:10,649] [DEBUG] Loading corpus from path: A-dev-ATTR-it1-fold2.spacy\n","[2021-05-11 15:26:10,650] [DEBUG] Loading corpus from path: A-train-ATTR-it1-fold2.spacy\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  --------  ------  ------  ------  ------\n","  0       0        4338.08    671.20    0.00    0.00    0.00    0.00\n","200     200       99440.15  29992.83   57.30   55.43   59.30    0.57\n","400     400          16.33    779.76   52.63   52.94   52.33    0.53\n","600     600          24.64    761.72   51.65   48.96   54.65    0.52\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","A-ATTR-it1-fold2/model-last\n","  adding: A-ATTR-it1-fold2/model-best/config.cfg (deflated 60%)\n","  adding: A-ATTR-it1-fold2/model-best/meta.json (deflated 58%)\n","  adding: A-ATTR-it1-fold2/model-best/ner/ (stored 0%)\n","  adding: A-ATTR-it1-fold2/model-best/ner/moves (deflated 46%)\n","  adding: A-ATTR-it1-fold2/model-best/ner/cfg (deflated 31%)\n","  adding: A-ATTR-it1-fold2/model-best/ner/model (deflated 8%)\n","  adding: A-ATTR-it1-fold2/model-best/tokenizer (deflated 81%)\n","  adding: A-ATTR-it1-fold2/model-best/transformer/ (stored 0%)\n","  adding: A-ATTR-it1-fold2/model-best/transformer/cfg (stored 0%)\n","  adding: A-ATTR-it1-fold2/model-best/transformer/model/ (stored 0%)\n","  adding: A-ATTR-it1-fold2/model-best/transformer/model/config.json (deflated 49%)\n","  adding: A-ATTR-it1-fold2/model-best/transformer/model/tokenizer_config.json (deflated 47%)\n","  adding: A-ATTR-it1-fold2/model-best/transformer/model/special_tokens_map.json (deflated 50%)\n","  adding: A-ATTR-it1-fold2/model-best/transformer/model/vocab.json (deflated 59%)\n","  adding: A-ATTR-it1-fold2/model-best/transformer/model/pytorch_model.bin (deflated 16%)\n","  adding: A-ATTR-it1-fold2/model-best/transformer/model/merges.txt (deflated 53%)\n","  adding: A-ATTR-it1-fold2/model-best/vocab/ (stored 0%)\n","  adding: A-ATTR-it1-fold2/model-best/vocab/key2row (stored 0%)\n","  adding: A-ATTR-it1-fold2/model-best/vocab/vectors (deflated 45%)\n","  adding: A-ATTR-it1-fold2/model-best/vocab/lookups.bin (deflated 43%)\n","  adding: A-ATTR-it1-fold2/model-best/vocab/strings.json (deflated 72%)\n","Training model for ATTR at fold 1\n","2021-05-11 15:32:01.950548: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","[2021-05-11 15:32:03,814] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev', 'training.patience']\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2021-05-11 15:32:04,532] [INFO] Set up nlp object from config\n","[2021-05-11 15:32:04,541] [DEBUG] Loading corpus from path: A-dev-ATTR-it2-fold1.spacy\n","[2021-05-11 15:32:04,542] [DEBUG] Loading corpus from path: A-train-ATTR-it2-fold1.spacy\n","[2021-05-11 15:32:04,542] [INFO] Pipeline: ['transformer', 'ner']\n","[2021-05-11 15:32:04,546] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm']\n","[2021-05-11 15:32:04,554] [INFO] Added vocab lookups: lexeme_norm\n","[2021-05-11 15:32:04,554] [INFO] Created vocabulary\n","[2021-05-11 15:32:04,554] [INFO] Finished initializing nlp object\n","[2021-05-11 15:32:11,928] [INFO] Initialized pipeline components: ['transformer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2021-05-11 15:32:11,941] [DEBUG] Loading corpus from path: A-dev-ATTR-it2-fold1.spacy\n","[2021-05-11 15:32:11,943] [DEBUG] Loading corpus from path: A-train-ATTR-it2-fold1.spacy\n","[2021-05-11 15:32:11,954] [DEBUG] Removed existing output directory: A-ATTR-it2-fold1/model-best\n","[2021-05-11 15:32:11,964] [DEBUG] Removed existing output directory: A-ATTR-it2-fold1/model-last\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  --------  ------  ------  ------  ------\n","  0       0        3469.32    398.60    0.30    0.31    0.29    0.00\n"," 13     200      158633.19  62340.19   60.73   59.73   61.77    0.61\n"," 26     400        4980.47   7057.84   60.50   62.01   59.06    0.60\n"," 39     600        1426.66   2348.46   59.71   60.92   58.56    0.60\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","A-ATTR-it2-fold1/model-last\n","  adding: A-ATTR-it2-fold1/model-best/config.cfg (deflated 60%)\n","  adding: A-ATTR-it2-fold1/model-best/meta.json (deflated 58%)\n","  adding: A-ATTR-it2-fold1/model-best/ner/ (stored 0%)\n","  adding: A-ATTR-it2-fold1/model-best/ner/moves (deflated 46%)\n","  adding: A-ATTR-it2-fold1/model-best/ner/cfg (deflated 31%)\n","  adding: A-ATTR-it2-fold1/model-best/ner/model (deflated 8%)\n","  adding: A-ATTR-it2-fold1/model-best/tokenizer (deflated 81%)\n","  adding: A-ATTR-it2-fold1/model-best/transformer/ (stored 0%)\n","  adding: A-ATTR-it2-fold1/model-best/transformer/cfg (stored 0%)\n","  adding: A-ATTR-it2-fold1/model-best/transformer/model/ (stored 0%)\n","  adding: A-ATTR-it2-fold1/model-best/transformer/model/config.json (deflated 49%)\n","  adding: A-ATTR-it2-fold1/model-best/transformer/model/tokenizer_config.json (deflated 47%)\n","  adding: A-ATTR-it2-fold1/model-best/transformer/model/special_tokens_map.json (deflated 50%)\n","  adding: A-ATTR-it2-fold1/model-best/transformer/model/vocab.json (deflated 59%)\n","  adding: A-ATTR-it2-fold1/model-best/transformer/model/pytorch_model.bin (deflated 15%)\n","  adding: A-ATTR-it2-fold1/model-best/transformer/model/merges.txt (deflated 53%)\n","  adding: A-ATTR-it2-fold1/model-best/vocab/ (stored 0%)\n","  adding: A-ATTR-it2-fold1/model-best/vocab/key2row (stored 0%)\n","  adding: A-ATTR-it2-fold1/model-best/vocab/vectors (deflated 45%)\n","  adding: A-ATTR-it2-fold1/model-best/vocab/lookups.bin (deflated 43%)\n","  adding: A-ATTR-it2-fold1/model-best/vocab/strings.json (deflated 73%)\n","Training model for ATTR at fold 2\n","2021-05-11 15:51:10.920808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","\u001b[38;5;2m✔ Created output directory: A-ATTR-it2-fold2\u001b[0m\n","[2021-05-11 15:51:12,533] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev', 'training.patience']\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2021-05-11 15:51:13,240] [INFO] Set up nlp object from config\n","[2021-05-11 15:51:13,249] [DEBUG] Loading corpus from path: A-dev-ATTR-it2-fold2.spacy\n","[2021-05-11 15:51:13,250] [DEBUG] Loading corpus from path: A-train-ATTR-it2-fold2.spacy\n","[2021-05-11 15:51:13,250] [INFO] Pipeline: ['transformer', 'ner']\n","[2021-05-11 15:51:13,254] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm']\n","[2021-05-11 15:51:13,262] [INFO] Added vocab lookups: lexeme_norm\n","[2021-05-11 15:51:13,262] [INFO] Created vocabulary\n","[2021-05-11 15:51:13,262] [INFO] Finished initializing nlp object\n","[2021-05-11 15:51:20,723] [INFO] Initialized pipeline components: ['transformer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2021-05-11 15:51:20,736] [DEBUG] Loading corpus from path: A-dev-ATTR-it2-fold2.spacy\n","[2021-05-11 15:51:20,737] [DEBUG] Loading corpus from path: A-train-ATTR-it2-fold2.spacy\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  --------  ------  ------  ------  ------\n","  0       0        3086.76    395.44    0.26    0.27    0.25    0.00\n"," 13     200      151944.46  61792.66   59.16   66.60   53.21    0.59\n"," 27     400        5307.97   7472.82   60.67   58.06   63.51    0.61\n"," 41     600        1471.19   2506.73   61.60   61.07   62.14    0.62\n"," 55     800         717.86   1585.85   61.41   63.76   59.22    0.61\n"," 69    1000         507.65   1329.26   60.78   60.97   60.59    0.61\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","A-ATTR-it2-fold2/model-last\n","  adding: A-ATTR-it2-fold2/model-best/config.cfg (deflated 60%)\n","  adding: A-ATTR-it2-fold2/model-best/meta.json (deflated 58%)\n","  adding: A-ATTR-it2-fold2/model-best/ner/ (stored 0%)\n","  adding: A-ATTR-it2-fold2/model-best/ner/moves (deflated 46%)\n","  adding: A-ATTR-it2-fold2/model-best/ner/cfg (deflated 31%)\n","  adding: A-ATTR-it2-fold2/model-best/ner/model (deflated 8%)\n","  adding: A-ATTR-it2-fold2/model-best/tokenizer (deflated 81%)\n","  adding: A-ATTR-it2-fold2/model-best/transformer/ (stored 0%)\n","  adding: A-ATTR-it2-fold2/model-best/transformer/cfg (stored 0%)\n","  adding: A-ATTR-it2-fold2/model-best/transformer/model/ (stored 0%)\n","  adding: A-ATTR-it2-fold2/model-best/transformer/model/config.json (deflated 49%)\n","  adding: A-ATTR-it2-fold2/model-best/transformer/model/tokenizer_config.json (deflated 47%)\n","  adding: A-ATTR-it2-fold2/model-best/transformer/model/special_tokens_map.json (deflated 50%)\n","  adding: A-ATTR-it2-fold2/model-best/transformer/model/vocab.json (deflated 59%)\n","  adding: A-ATTR-it2-fold2/model-best/transformer/model/pytorch_model.bin (deflated 14%)\n","  adding: A-ATTR-it2-fold2/model-best/transformer/model/merges.txt (deflated 53%)\n","  adding: A-ATTR-it2-fold2/model-best/vocab/ (stored 0%)\n","  adding: A-ATTR-it2-fold2/model-best/vocab/key2row (stored 0%)\n","  adding: A-ATTR-it2-fold2/model-best/vocab/vectors (deflated 45%)\n","  adding: A-ATTR-it2-fold2/model-best/vocab/lookups.bin (deflated 43%)\n","  adding: A-ATTR-it2-fold2/model-best/vocab/strings.json (deflated 73%)\n","Training model for ATTR at fold 1\n","2021-05-11 16:02:42.147913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","\u001b[38;5;2m✔ Created output directory: A-ATTR-it3-fold1\u001b[0m\n","[2021-05-11 16:02:43,848] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev', 'training.patience']\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2021-05-11 16:02:44,561] [INFO] Set up nlp object from config\n","[2021-05-11 16:02:44,571] [DEBUG] Loading corpus from path: A-dev-ATTR-it3-fold1.spacy\n","[2021-05-11 16:02:44,571] [DEBUG] Loading corpus from path: A-train-ATTR-it3-fold1.spacy\n","[2021-05-11 16:02:44,572] [INFO] Pipeline: ['transformer', 'ner']\n","[2021-05-11 16:02:44,576] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm']\n","[2021-05-11 16:02:44,585] [INFO] Added vocab lookups: lexeme_norm\n","[2021-05-11 16:02:44,585] [INFO] Created vocabulary\n","[2021-05-11 16:02:44,585] [INFO] Finished initializing nlp object\n","[2021-05-11 16:02:52,042] [INFO] Initialized pipeline components: ['transformer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2021-05-11 16:02:52,051] [DEBUG] Loading corpus from path: A-dev-ATTR-it3-fold1.spacy\n","[2021-05-11 16:02:52,052] [DEBUG] Loading corpus from path: A-train-ATTR-it3-fold1.spacy\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  --------  ------  ------  ------  ------\n","  0       0        3469.32    398.60    0.30    0.31    0.29    0.00\n"," 13     200      158576.51  62262.82   61.49   60.69   62.31    0.61\n"," 26     400        5139.83   7144.23   60.06   59.41   60.73    0.60\n"," 39     600        1460.74   2375.69   59.96   59.73   60.18    0.60\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","A-ATTR-it3-fold1/model-last\n","  adding: A-ATTR-it3-fold1/model-best/config.cfg (deflated 60%)\n","  adding: A-ATTR-it3-fold1/model-best/meta.json (deflated 57%)\n","  adding: A-ATTR-it3-fold1/model-best/ner/ (stored 0%)\n","  adding: A-ATTR-it3-fold1/model-best/ner/moves (deflated 46%)\n","  adding: A-ATTR-it3-fold1/model-best/ner/cfg (deflated 31%)\n","  adding: A-ATTR-it3-fold1/model-best/ner/model (deflated 8%)\n","  adding: A-ATTR-it3-fold1/model-best/tokenizer (deflated 81%)\n","  adding: A-ATTR-it3-fold1/model-best/transformer/ (stored 0%)\n","  adding: A-ATTR-it3-fold1/model-best/transformer/cfg (stored 0%)\n","  adding: A-ATTR-it3-fold1/model-best/transformer/model/ (stored 0%)\n","  adding: A-ATTR-it3-fold1/model-best/transformer/model/config.json (deflated 49%)\n","  adding: A-ATTR-it3-fold1/model-best/transformer/model/tokenizer_config.json (deflated 47%)\n","  adding: A-ATTR-it3-fold1/model-best/transformer/model/special_tokens_map.json (deflated 50%)\n","  adding: A-ATTR-it3-fold1/model-best/transformer/model/vocab.json (deflated 59%)\n","  adding: A-ATTR-it3-fold1/model-best/transformer/model/pytorch_model.bin (deflated 15%)\n","  adding: A-ATTR-it3-fold1/model-best/transformer/model/merges.txt (deflated 53%)\n","  adding: A-ATTR-it3-fold1/model-best/vocab/ (stored 0%)\n","  adding: A-ATTR-it3-fold1/model-best/vocab/key2row (stored 0%)\n","  adding: A-ATTR-it3-fold1/model-best/vocab/vectors (deflated 45%)\n","  adding: A-ATTR-it3-fold1/model-best/vocab/lookups.bin (deflated 43%)\n","  adding: A-ATTR-it3-fold1/model-best/vocab/strings.json (deflated 73%)\n","Training model for ATTR at fold 2\n","2021-05-11 16:10:12.439833: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","\u001b[38;5;2m✔ Created output directory: A-ATTR-it3-fold2\u001b[0m\n","[2021-05-11 16:10:14,236] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev', 'training.patience']\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2021-05-11 16:10:14,974] [INFO] Set up nlp object from config\n","[2021-05-11 16:10:14,983] [DEBUG] Loading corpus from path: A-dev-ATTR-it3-fold2.spacy\n","[2021-05-11 16:10:14,984] [DEBUG] Loading corpus from path: A-train-ATTR-it3-fold2.spacy\n","[2021-05-11 16:10:14,984] [INFO] Pipeline: ['transformer', 'ner']\n","[2021-05-11 16:10:14,989] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm']\n","[2021-05-11 16:10:14,997] [INFO] Added vocab lookups: lexeme_norm\n","[2021-05-11 16:10:14,998] [INFO] Created vocabulary\n","[2021-05-11 16:10:14,998] [INFO] Finished initializing nlp object\n","[2021-05-11 16:10:22,157] [INFO] Initialized pipeline components: ['transformer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2021-05-11 16:10:22,168] [DEBUG] Loading corpus from path: A-dev-ATTR-it3-fold2.spacy\n","[2021-05-11 16:10:22,168] [DEBUG] Loading corpus from path: A-train-ATTR-it3-fold2.spacy\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  --------  ------  ------  ------  ------\n","  0       0        3086.76    395.44    0.26    0.27    0.25    0.00\n"," 13     200      151957.14  61787.86   61.07   64.74   57.80    0.61\n"," 27     400        5141.84   7329.33   59.87   56.59   63.55    0.60\n"," 41     600        1504.88   2553.36   61.17   60.79   61.55    0.61\n"," 55     800         761.08   1658.72   61.21   61.25   61.18    0.61\n"," 69    1000         497.33   1291.71   61.61   63.02   60.26    0.62\n"," 83    1200         378.64   1131.07   61.12   62.09   60.18    0.61\n"," 96    1400         384.53   1065.95   60.74   62.16   59.38    0.61\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","A-ATTR-it3-fold2/model-last\n","  adding: A-ATTR-it3-fold2/model-best/config.cfg (deflated 60%)\n","  adding: A-ATTR-it3-fold2/model-best/meta.json (deflated 58%)\n","  adding: A-ATTR-it3-fold2/model-best/ner/ (stored 0%)\n","  adding: A-ATTR-it3-fold2/model-best/ner/moves (deflated 46%)\n","  adding: A-ATTR-it3-fold2/model-best/ner/cfg (deflated 31%)\n","  adding: A-ATTR-it3-fold2/model-best/ner/model (deflated 8%)\n","  adding: A-ATTR-it3-fold2/model-best/tokenizer (deflated 81%)\n","  adding: A-ATTR-it3-fold2/model-best/transformer/ (stored 0%)\n","  adding: A-ATTR-it3-fold2/model-best/transformer/cfg (stored 0%)\n","  adding: A-ATTR-it3-fold2/model-best/transformer/model/ (stored 0%)\n","  adding: A-ATTR-it3-fold2/model-best/transformer/model/config.json (deflated 49%)\n","  adding: A-ATTR-it3-fold2/model-best/transformer/model/tokenizer_config.json (deflated 47%)\n","  adding: A-ATTR-it3-fold2/model-best/transformer/model/special_tokens_map.json (deflated 50%)\n","  adding: A-ATTR-it3-fold2/model-best/transformer/model/vocab.json (deflated 59%)\n","  adding: A-ATTR-it3-fold2/model-best/transformer/model/pytorch_model.bin (deflated 14%)\n","  adding: A-ATTR-it3-fold2/model-best/transformer/model/merges.txt (deflated 53%)\n","  adding: A-ATTR-it3-fold2/model-best/vocab/ (stored 0%)\n","  adding: A-ATTR-it3-fold2/model-best/vocab/key2row (stored 0%)\n","  adding: A-ATTR-it3-fold2/model-best/vocab/vectors (deflated 45%)\n","  adding: A-ATTR-it3-fold2/model-best/vocab/lookups.bin (deflated 43%)\n","  adding: A-ATTR-it3-fold2/model-best/vocab/strings.json (deflated 73%)\n","Training model for ATTR at fold 1\n","2021-05-11 16:26:06.612501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","\u001b[38;5;2m✔ Created output directory: A-ATTR-it4-fold1\u001b[0m\n","[2021-05-11 16:26:08,330] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev', 'training.patience']\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2021-05-11 16:26:09,042] [INFO] Set up nlp object from config\n","[2021-05-11 16:26:09,051] [DEBUG] Loading corpus from path: A-dev-ATTR-it4-fold1.spacy\n","[2021-05-11 16:26:09,052] [DEBUG] Loading corpus from path: A-train-ATTR-it4-fold1.spacy\n","[2021-05-11 16:26:09,052] [INFO] Pipeline: ['transformer', 'ner']\n","[2021-05-11 16:26:09,056] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm']\n","[2021-05-11 16:26:09,065] [INFO] Added vocab lookups: lexeme_norm\n","[2021-05-11 16:26:09,065] [INFO] Created vocabulary\n","[2021-05-11 16:26:09,065] [INFO] Finished initializing nlp object\n","[2021-05-11 16:26:16,343] [INFO] Initialized pipeline components: ['transformer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2021-05-11 16:26:16,357] [DEBUG] Loading corpus from path: A-dev-ATTR-it4-fold1.spacy\n","[2021-05-11 16:26:16,359] [DEBUG] Loading corpus from path: A-train-ATTR-it4-fold1.spacy\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  --------  ------  ------  ------  ------\n","  0       0        3469.32    398.60    0.30    0.31    0.29    0.00\n"," 13     200      158762.91  62501.31   61.81   62.57   61.06    0.62\n"," 26     400        5182.58   7289.30   60.31   59.12   61.56    0.60\n"," 39     600        1599.81   2483.53   59.65   60.52   58.81    0.60\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","A-ATTR-it4-fold1/model-last\n","  adding: A-ATTR-it4-fold1/model-best/config.cfg (deflated 60%)\n","  adding: A-ATTR-it4-fold1/model-best/meta.json (deflated 58%)\n","  adding: A-ATTR-it4-fold1/model-best/ner/ (stored 0%)\n","  adding: A-ATTR-it4-fold1/model-best/ner/moves (deflated 46%)\n","  adding: A-ATTR-it4-fold1/model-best/ner/cfg (deflated 31%)\n","  adding: A-ATTR-it4-fold1/model-best/ner/model (deflated 8%)\n","  adding: A-ATTR-it4-fold1/model-best/tokenizer (deflated 81%)\n","  adding: A-ATTR-it4-fold1/model-best/transformer/ (stored 0%)\n","  adding: A-ATTR-it4-fold1/model-best/transformer/cfg (stored 0%)\n","  adding: A-ATTR-it4-fold1/model-best/transformer/model/ (stored 0%)\n","  adding: A-ATTR-it4-fold1/model-best/transformer/model/config.json (deflated 49%)\n","  adding: A-ATTR-it4-fold1/model-best/transformer/model/tokenizer_config.json (deflated 47%)\n","  adding: A-ATTR-it4-fold1/model-best/transformer/model/special_tokens_map.json (deflated 50%)\n","  adding: A-ATTR-it4-fold1/model-best/transformer/model/vocab.json (deflated 59%)\n","  adding: A-ATTR-it4-fold1/model-best/transformer/model/pytorch_model.bin (deflated 15%)\n","  adding: A-ATTR-it4-fold1/model-best/transformer/model/merges.txt (deflated 53%)\n","  adding: A-ATTR-it4-fold1/model-best/vocab/ (stored 0%)\n","  adding: A-ATTR-it4-fold1/model-best/vocab/key2row (stored 0%)\n","  adding: A-ATTR-it4-fold1/model-best/vocab/vectors (deflated 45%)\n","  adding: A-ATTR-it4-fold1/model-best/vocab/lookups.bin (deflated 43%)\n","  adding: A-ATTR-it4-fold1/model-best/vocab/strings.json (deflated 73%)\n","Training model for ATTR at fold 2\n","2021-05-11 16:45:29.291598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","\u001b[38;5;2m✔ Created output directory: A-ATTR-it4-fold2\u001b[0m\n","[2021-05-11 16:45:31,055] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev', 'training.patience']\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2021-05-11 16:45:31,756] [INFO] Set up nlp object from config\n","[2021-05-11 16:45:31,766] [DEBUG] Loading corpus from path: A-dev-ATTR-it4-fold2.spacy\n","[2021-05-11 16:45:31,766] [DEBUG] Loading corpus from path: A-train-ATTR-it4-fold2.spacy\n","[2021-05-11 16:45:31,767] [INFO] Pipeline: ['transformer', 'ner']\n","[2021-05-11 16:45:31,771] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm']\n","[2021-05-11 16:45:31,779] [INFO] Added vocab lookups: lexeme_norm\n","[2021-05-11 16:45:31,779] [INFO] Created vocabulary\n","[2021-05-11 16:45:31,779] [INFO] Finished initializing nlp object\n","[2021-05-11 16:45:39,412] [INFO] Initialized pipeline components: ['transformer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2021-05-11 16:45:39,425] [DEBUG] Loading corpus from path: A-dev-ATTR-it4-fold2.spacy\n","[2021-05-11 16:45:39,426] [DEBUG] Loading corpus from path: A-train-ATTR-it4-fold2.spacy\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  --------  ------  ------  ------  ------\n","  0       0        3086.76    395.44    0.26    0.27    0.25    0.00\n"," 13     200      151949.04  61807.47   61.01   64.38   57.96    0.61\n"," 27     400        5193.69   7459.80   61.90   61.31   62.51    0.62\n"," 41     600        1550.55   2613.26   61.33   59.40   63.39    0.61\n"," 55     800         750.41   1670.32   61.21   62.74   59.76    0.61\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","A-ATTR-it4-fold2/model-last\n","  adding: A-ATTR-it4-fold2/model-best/config.cfg (deflated 60%)\n","  adding: A-ATTR-it4-fold2/model-best/meta.json (deflated 58%)\n","  adding: A-ATTR-it4-fold2/model-best/ner/ (stored 0%)\n","  adding: A-ATTR-it4-fold2/model-best/ner/moves (deflated 46%)\n","  adding: A-ATTR-it4-fold2/model-best/ner/cfg (deflated 31%)\n","  adding: A-ATTR-it4-fold2/model-best/ner/model (deflated 8%)\n","  adding: A-ATTR-it4-fold2/model-best/tokenizer (deflated 81%)\n","  adding: A-ATTR-it4-fold2/model-best/transformer/ (stored 0%)\n","  adding: A-ATTR-it4-fold2/model-best/transformer/cfg (stored 0%)\n","  adding: A-ATTR-it4-fold2/model-best/transformer/model/ (stored 0%)\n","  adding: A-ATTR-it4-fold2/model-best/transformer/model/config.json (deflated 49%)\n","  adding: A-ATTR-it4-fold2/model-best/transformer/model/tokenizer_config.json (deflated 47%)\n","  adding: A-ATTR-it4-fold2/model-best/transformer/model/special_tokens_map.json (deflated 50%)\n","  adding: A-ATTR-it4-fold2/model-best/transformer/model/vocab.json (deflated 59%)\n","  adding: A-ATTR-it4-fold2/model-best/transformer/model/pytorch_model.bin (deflated 15%)\n","  adding: A-ATTR-it4-fold2/model-best/transformer/model/merges.txt (deflated 53%)\n","  adding: A-ATTR-it4-fold2/model-best/vocab/ (stored 0%)\n","  adding: A-ATTR-it4-fold2/model-best/vocab/key2row (stored 0%)\n","  adding: A-ATTR-it4-fold2/model-best/vocab/vectors (deflated 45%)\n","  adding: A-ATTR-it4-fold2/model-best/vocab/lookups.bin (deflated 43%)\n","  adding: A-ATTR-it4-fold2/model-best/vocab/strings.json (deflated 73%)\n","Training model for ATTR at fold 1\n","2021-05-11 17:09:42.730314: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","\u001b[38;5;2m✔ Created output directory: A-ATTR-it5-fold1\u001b[0m\n","[2021-05-11 17:09:44,359] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev', 'training.patience']\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2021-05-11 17:09:45,079] [INFO] Set up nlp object from config\n","[2021-05-11 17:09:45,088] [DEBUG] Loading corpus from path: A-dev-ATTR-it5-fold1.spacy\n","[2021-05-11 17:09:45,089] [DEBUG] Loading corpus from path: A-train-ATTR-it5-fold1.spacy\n","[2021-05-11 17:09:45,089] [INFO] Pipeline: ['transformer', 'ner']\n","[2021-05-11 17:09:45,093] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm']\n","[2021-05-11 17:09:45,101] [INFO] Added vocab lookups: lexeme_norm\n","[2021-05-11 17:09:45,101] [INFO] Created vocabulary\n","[2021-05-11 17:09:45,101] [INFO] Finished initializing nlp object\n","[2021-05-11 17:09:52,732] [INFO] Initialized pipeline components: ['transformer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2021-05-11 17:09:52,749] [DEBUG] Loading corpus from path: A-dev-ATTR-it5-fold1.spacy\n","[2021-05-11 17:09:52,751] [DEBUG] Loading corpus from path: A-train-ATTR-it5-fold1.spacy\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  --------  ------  ------  ------  ------\n","  0       0        3469.32    398.60    0.30    0.31    0.29    0.00\n"," 13     200      158804.98  62518.86   60.36   63.81   57.26    0.60\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q5o-MuLt53MT"},"source":["!cp \"$exp_name-logfile.txt\" \"drive/MyDrive/ner/$exp_name/$label/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWqsNj6CbSI5"},"source":[""],"execution_count":null,"outputs":[]}]}